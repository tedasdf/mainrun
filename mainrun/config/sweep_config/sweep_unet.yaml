name: unet gpt sweep 
program: train.py
method: random   # or grid, or bayes
metric:
  name: val/loss
  goal: minimize

parameters:
  hyperparams.model_architecture:
    value: unet_gpt
  
  
  hyperparams.optimizer:
    values: ["sgd", "adamw", "adagrad"]

  hyperparams.lr:
    values: [ 0.012 , 0.01 , 0.015]


  model_configs.unet_gpt.dropout:
    values: [0.1, 0.3, 0.5 ]
  
  hyperparams.weight_decay:
    values: [0.0, 0.1 , 0.2, 0.5 , 0.7 ]

  # Bottleneck sizes to try (sequence per layer)
  model_configs.unet_gpt.hidden_layer_list:
    values:
      - [512, 384, 256, 192, 192, 256, 384, 512]
      - [512, 384, 256, 128, 128, 256, 384, 512]
      - [256, 192, 128, 64, 64, 128, 192, 256]
      - [512, 256, 128, 64, 64, 128, 256, 512]

  model_configs.unet_gpt.d_model:
    values: [128, 256, 512 ]


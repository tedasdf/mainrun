{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a35e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\teeds\\miniconda3\\envs\\llm_train\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "num_titles = 10000\n",
    "val_frac = 0.1\n",
    "seed = 1337\n",
    "ds = load_dataset(\"julien040/hacker-news-posts\", split=\"train\", cache_dir=\"./data\").shuffle(seed=seed)\n",
    "titles = [row[\"title\"].strip() for row in ds.take(num_titles)]\n",
    "n = int(num_titles * (1 - val_frac))\n",
    "train_titles, val_titles= titles[:n], titles[n:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77977d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TITLES\n",
      "Doom on Ubuntu Phone\n",
      "VAL TITles\n",
      "New Twists in the Road to Quantum Supremacy\n"
     ]
    }
   ],
   "source": [
    "print('Train TITLES')\n",
    "print(train_titles[0])\n",
    "print('VAL TITles')\n",
    "print(val_titles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4c0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, decoders, models, pre_tokenizers, trainers    \n",
    "\n",
    "\n",
    "def train_tokenizer(titles: list[str], vocab_size: int, unk_token: str = \"<unk>\", pad_token: str = \"<pad>\", eos_token: str = \"<eos>\") -> Tokenizer:\n",
    "    tokenizer = Tokenizer(models.BPE(unk_token=unk_token))\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        special_tokens=[pad_token, eos_token, unk_token]\n",
    "    )\n",
    "    tokenizer.train_from_iterator(titles, trainer)\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_batch(split_ids: torch.Tensor, ptr: int, block_size: int, batch_size: int, device: torch.device):\n",
    "    span = block_size * batch_size + 1\n",
    "    if ptr + span >= len(split_ids):\n",
    "        ptr = 0\n",
    "    batch = split_ids[ptr: ptr + span]\n",
    "    x = batch[:-1].view(batch_size, block_size).to(device)\n",
    "    y = batch[1:].view(batch_size, block_size).to(device)\n",
    "    return x, y, ptr + block_size * batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a5b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenizer(train_titles+val_titles, vocab_size, eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d80728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.tokenizer.BPETokenizer import BPETokenizer\n",
    "tok = BPETokenizer(train_tokenizer(train_titles+val_titles, vocab_size, eos_token=\"<eos>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9056ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token=\"<eos>\"\n",
    "train_text = eos_token.join(train_titles) + eos_token\n",
    "val_text = eos_token.join(val_titles) + eos_token\n",
    "train_ids = torch.tensor(tok.encode(train_text), dtype=torch.long)\n",
    "val_ids = torch.tensor(tok.encode(val_text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b176b84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_titles) , len(val_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8133c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doom on Ubuntu Phone'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04950b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([107337]), torch.Size([11963]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids.shape, val_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba10127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6130,   274,  1866,  1723,     1,  5115,  5482,   246,  1228, 10936])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d04ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6baf86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "num_titles = 10000\n",
    "val_frac = 0.1\n",
    "seed = 1337\n",
    "ds = load_dataset(\"julien040/hacker-news-posts\", split=\"train\", cache_dir=\"./data\").shuffle(seed=seed)\n",
    "titles = [row[\"title\"].strip() for row in ds.take(num_titles)]\n",
    "n = int(num_titles * (1 - val_frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46925a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Hyperparameters:\n",
    "\n",
    "    seed: int\n",
    "    epochs: int\n",
    "    val_frac: float\n",
    "    num_titles: int\n",
    "    vocab_size: int\n",
    "    context_length: int  # Added context_length parameter\n",
    "\n",
    "    log_file: str\n",
    "    model_architecture: str \n",
    "    \n",
    "    batch_size: int\n",
    "    lr: float\n",
    "    weight_decay: float\n",
    "    scheduler: str # none, linear, cosine\n",
    "    optimizer: str\n",
    "    evals_per_epoch: float\n",
    "\n",
    "\n",
    "from model.gpt import GPT, GPTConfig\n",
    "\n",
    "@dataclass\n",
    "class AttnConfig:\n",
    "    d_model: int\n",
    "    n_head: int\n",
    "    block_size: int\n",
    "    dropout: float\n",
    "\n",
    "cfg = OmegaConf.load(\"config/hyperparams.yaml\")\n",
    "            # Update cfg with args\n",
    "\n",
    "hparams = OmegaConf.to_container(cfg.hyperparams, resolve=True)\n",
    "modelparams = OmegaConf.to_container(cfg.model_configs[hparams['model_architecture']], resolve=True)\n",
    "attnparams = OmegaConf.to_container(cfg.attn_configs[modelparams['attention_layer']], resolve=True)\n",
    "\n",
    "args = Hyperparameters(**hparams)\n",
    "\n",
    "attn = AttnConfig(\n",
    "    d_model=modelparams['d_model'],\n",
    "    n_head=attnparams['n_head'],\n",
    "    block_size=args.context_length,\n",
    "    dropout=modelparams['dropout']\n",
    ")\n",
    "\n",
    "cfg = GPTConfig(\n",
    "    vocab_size=args.vocab_size,\n",
    "    block_size=args.context_length,\n",
    "    attn_config = attn,\n",
    "    activation_function = 'gelu',\n",
    "    **modelparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f943360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9279f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum p = 3.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float32 \n",
    "BATCH = 1\n",
    "SEQ = 10\n",
    "DIM = 2\n",
    "\n",
    "# ... your setup ...\n",
    "u = torch.randn(BATCH, SEQ , dtype=dtype)\n",
    "z = u\n",
    "k = 3\n",
    "zminus = z - 1\n",
    "\n",
    "# Merge zminus and z to find beta candidates (for the *same* batch as we'll use below)\n",
    "merged_tensor = torch.cat((z, z - 1), dim=1)\n",
    "merged_sorted_tensor, _ = torch.sort(merged_tensor, descending=True)\n",
    "merged_sorted_tensor = merged_sorted_tensor[0]\n",
    "\n",
    "# Sort z (descending) for the same batch\n",
    "z, _ = torch.sort(z, descending=True)\n",
    "z = z[0]                                  # 1D scores (length m)\n",
    "m = z.numel()\n",
    "\n",
    "# Cumulative sums and sentinel padding\n",
    "z_cum = torch.cumsum(z, dim=0)            # S[t] = sum_{i=0..t} z[i]\n",
    "z_pad = torch.cat([z, z.new_tensor([-float('inf')])])  # z[m] = -inf for right-guard\n",
    "\n",
    "pairs = []  # will store (U_count, W_count) as *counts*\n",
    "for beta in merged_sorted_tensor:\n",
    "    b = beta.item()\n",
    "\n",
    "    # masks over sorted z\n",
    "    u_ge_mask = (z >= b + 1)      # will be True for indices [0 .. U-1]\n",
    "    w_gt_mask = (z > b)           # will be True for indices [0 .. W-1]\n",
    "\n",
    "    U = int(u_ge_mask.sum().item())   # <-- counts, not indices\n",
    "    W = int(w_gt_mask.sum().item())   # <-- counts, not indices\n",
    "    if W <= U:                        # need at least one fractional slot\n",
    "        continue\n",
    "\n",
    "    pairs.append((U, W))\n",
    "\n",
    "# scan in the paper's order: descending in beta (pairs already collected that way)\n",
    "tau = None\n",
    "for U, W in pairs:\n",
    "    # sums over i in [U .. W-1] using zero-based inclusive prefix sums:\n",
    "    # sum_{U..W-1} z = z_cum[W-1] - (z_cum[U-1] if U>0 else 0)\n",
    "    seg_sum = z_cum[W-1] - (z_cum[U-1] if U > 0 else z_cum.new_zeros(()))\n",
    "    tau_cand = (seg_sum + (U - k)) / (W - U)\n",
    "\n",
    "    # interval checks (use sentinels; interpret counts -> 0-based indices)\n",
    "    left_ok  = (z[W-1] > tau_cand) if W >= 1 else True\n",
    "    right_ok = (tau_cand >= z_pad[W])  # z_pad[W] is safe for W==m\n",
    "    up_ok    = (z[U-1] >= tau_cand + 1) if U >= 1 else True\n",
    "    down_ok  = ((tau_cand + 1) > z_pad[U])  # z_pad[U] safe for U==m\n",
    "\n",
    "    if left_ok and right_ok and up_ok and down_ok:\n",
    "        tau = tau_cand\n",
    "        break\n",
    "\n",
    "if tau is None:\n",
    "    print('hello')\n",
    "    # (extremely rare) fallback: bisection on tau\n",
    "    lo = (z.min() - 1).item()\n",
    "    hi = z.max().item()\n",
    "    for _ in range(60):\n",
    "        mid = (lo + hi) / 2.0\n",
    "        s = torch.clamp(z - mid, 0, 1).sum().item()\n",
    "        if s > k:   # need larger tau to shrink sum\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "    tau = torch.tensor((lo + hi) / 2.0, dtype=z.dtype, device=z.device)\n",
    "\n",
    "p = torch.clamp(z - tau, 0, 1)\n",
    "print(\"sum p =\", float(p.sum()))\n",
    "# p is for the sorted z[0]; map it back to your original order if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c886b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

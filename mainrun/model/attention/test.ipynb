{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2631ec0c",
   "metadata": {},
   "source": [
    "## SparseMAX "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef6fed",
   "metadata": {},
   "source": [
    "let delta^(K-1) = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4c544a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sparsemax activation function.\n",
    "\n",
    "Pytorch implementation of Sparsemax function from:\n",
    "-- \"From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification\"\n",
    "-- André F. T. Martins, Ramón Fernandez Astudillo (http://arxiv.org/abs/1602.02068)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class Sparsemax(nn.Module):\n",
    "    \"\"\"Sparsemax function.\"\"\"\n",
    "\n",
    "    def __init__(self, dim=None):\n",
    "        \"\"\"Initialize sparsemax activation\n",
    "        \n",
    "        Args:\n",
    "            dim (int, optional): The dimension over which to apply the sparsemax function.\n",
    "        \"\"\"\n",
    "        super(Sparsemax, self).__init__()\n",
    "\n",
    "        self.dim = -1 if dim is None else dim\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward function.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor. First dimension should be the batch size\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: [batch_size x number_of_logits] Output tensor\n",
    "\n",
    "        \"\"\"\n",
    "        # Sparsemax currently only handles 2-dim tensors,\n",
    "        # so we reshape to a convenient shape and reshape back after sparsemax\n",
    "        input = input.transpose(0, self.dim)\n",
    "        original_size = input.size()\n",
    "        input = input.reshape(input.size(0), -1)\n",
    "        input = input.transpose(0, 1)\n",
    "        dim = 1\n",
    "\n",
    "        number_of_logits = input.size(dim)\n",
    "\n",
    "        # Translate input by max for numerical stability\n",
    "        input = input - torch.max(input, dim=dim, keepdim=True)[0].expand_as(input)\n",
    "\n",
    "        # Sort input in descending order.\n",
    "        # (NOTE: Can be replaced with linear time selection method described here:\n",
    "        # http://stanford.edu/~jduchi/projects/DuchiShSiCh08.html)\n",
    "        zs = torch.sort(input=input, dim=dim, descending=True)[0]\n",
    "        range = torch.arange(start=1, end=number_of_logits + 1, step=1, device=device, dtype=input.dtype).view(1, -1)\n",
    "        range = range.expand_as(zs)\n",
    "\n",
    "        # Determine sparsity of projection\n",
    "        bound = 1 + range * zs\n",
    "        cumulative_sum_zs = torch.cumsum(zs, dim)\n",
    "        is_gt = torch.gt(bound, cumulative_sum_zs).type(input.type())\n",
    "        k = torch.max(is_gt * range, dim, keepdim=True)[0]\n",
    "\n",
    "        # Compute threshold function\n",
    "        zs_sparse = is_gt * zs\n",
    "\n",
    "        # Compute taus\n",
    "        taus = (torch.sum(zs_sparse, dim, keepdim=True) - 1) / k\n",
    "        taus = taus.expand_as(input)\n",
    "\n",
    "        # Sparsemax\n",
    "        self.output = torch.max(torch.zeros_like(input), input - taus)\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        output = self.output\n",
    "        output = output.transpose(0, 1)\n",
    "        output = output.reshape(original_size)\n",
    "        output = output.transpose(0, self.dim)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Backward function.\"\"\"\n",
    "        dim = 1\n",
    "\n",
    "        nonzeros = torch.ne(self.output, 0)\n",
    "        sum = torch.sum(grad_output * nonzeros, dim=dim) / torch.sum(nonzeros, dim=dim)\n",
    "        self.grad_input = nonzeros * (grad_output - sum.expand_as(grad_output))\n",
    "\n",
    "        return self.grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "39fea2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logits\n",
      "tensor([[-0.2096,  0.4682, -1.0835,  1.2378, -0.9220],\n",
      "        [-0.3716,  0.0984, -0.4024, -0.1276, -0.7100]])\n",
      "\n",
      "Sparsemax probabilities\n",
      "tensor([[0.0000, 0.1152, 0.0000, 0.8848, 0.0000],\n",
      "        [0.0792, 0.5492, 0.0484, 0.3232, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sparsemax = Sparsemax(dim=1)\n",
    "\n",
    "logits = torch.randn(2, 5)\n",
    "print(\"\\nLogits\")\n",
    "print(logits)\n",
    "\n",
    "sparsemax_probs = sparsemax(logits)\n",
    "print(\"\\nSparsemax probabilities\")\n",
    "print(sparsemax_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5d5a21d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2096,  0.4682, -1.0835,  1.2378, -0.9220],\n",
      "        [-0.3716,  0.0984, -0.4024, -0.1276, -0.7100]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (BATCH X SEQ)\n",
    "dtype = torch.float32 \n",
    "BATCH = 2\n",
    "SEQ = 5\n",
    "\n",
    "u = logits\n",
    "\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "df910b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0534c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n",
      "torch.Size([5, 2])\n",
      "torch.Size([2, 5])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "input = u\n",
    "input = input.transpose(0,-1)\n",
    "original_size = input.size()\n",
    "print(original_size)\n",
    "input = input.reshape(input.size(0), -1)\n",
    "print(input.size())\n",
    "input = input.transpose(0, 1)\n",
    "print(input.size())\n",
    "dim = 1\n",
    "\n",
    "number_of_logits = input.size(dim)\n",
    "print(number_of_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "781bbe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4474, -0.7696, -2.3213,  0.0000, -2.1598],\n",
      "        [-0.4700,  0.0000, -0.5008, -0.2260, -0.8084]])\n"
     ]
    }
   ],
   "source": [
    "input = input - torch.max(input, dim=dim, keepdim=True)[0].expand_as(input)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "644424fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -0.7696, -1.4474, -2.1598, -2.3213],\n",
      "        [ 0.0000, -0.2260, -0.4700, -0.5008, -0.8084]])\n",
      "tensor([[1., 2., 3., 4., 5.]])\n",
      "tensor([[1., 2., 3., 4., 5.],\n",
      "        [1., 2., 3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Sort input in descending order.\n",
    "# (NOTE: Can be replaced with linear time selection method described here:\n",
    "# http://stanford.edu/~jduchi/projects/DuchiShSiCh08.html)\n",
    "zs = torch.sort(input=input, dim=dim, descending=True)[0]\n",
    "print(zs)\n",
    "range = torch.arange(start=1, end=number_of_logits + 1, step=1, dtype=input.dtype).view(1, -1)\n",
    "print(range)\n",
    "range = range.expand_as(zs)\n",
    "print(range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3b2583ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.0000,  -0.5392,  -3.3423,  -7.6391, -10.6063],\n",
      "        [  1.0000,   0.5480,  -0.4100,  -1.0032,  -3.0419]])\n",
      "tensor([[ 0.0000, -0.7696, -2.2170, -4.3768, -6.6981],\n",
      "        [ 0.0000, -0.2260, -0.6960, -1.1968, -2.0052]])\n"
     ]
    }
   ],
   "source": [
    "# Determine sparsity of projection\n",
    "bound = 1 + range * zs\n",
    "print(bound)\n",
    "cumulative_sum_zs = torch.cumsum(zs, dim)\n",
    "print(cumulative_sum_zs)\n",
    "is_gt = torch.gt(bound, cumulative_sum_zs).type(input.type())\n",
    "k = torch.max(is_gt * range, dim, keepdim=True)[0]\n",
    "\n",
    "# Compute threshold function\n",
    "zs_sparse = is_gt * zs\n",
    "\n",
    "# Compute taus\n",
    "taus = (torch.sum(zs_sparse, dim, keepdim=True) - 1) / k\n",
    "taus = taus.expand_as(input)\n",
    "\n",
    "# Sparsemax\n",
    "output = torch.max(torch.zeros_like(input), input - taus)\n",
    "\n",
    "# Reshape back to original shape\n",
    "output_replication = output\n",
    "output = output.transpose(0, 1)\n",
    "output = output.reshape(original_size)\n",
    "output = output.transpose(0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "272d9d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1152, 0.0000, 0.8848, 0.0000],\n",
      "        [0.0792, 0.5492, 0.0484, 0.3232, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb5560",
   "metadata": {},
   "source": [
    "## Sparse K attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1047c",
   "metadata": {},
   "source": [
    "### The differentiable SparseK Operator\n",
    "\n",
    "![Sparse Attention](./asset/SparseKimage.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "942ee39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0723, -1.0590,  0.3733,  0.2973, -0.5252, -0.4214,  1.2907, -0.3438,\n",
      "         -0.9316, -1.6184]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float32 \n",
    "BATCH = 1\n",
    "SEQ = 10\n",
    "DIM = 2\n",
    "\n",
    "# (BATCH X SEQ)\n",
    "\n",
    "u = torch.randn(BATCH, SEQ , dtype=dtype)\n",
    "\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b345cae",
   "metadata": {},
   "source": [
    "\n",
    "![W and U ](./asset/uandw.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float32 \n",
    "BATCH = 1\n",
    "SEQ = 10\n",
    "DIM = 2\n",
    "# ...  setup ...\n",
    "u = torch.randn(BATCH, SEQ , dtype=dtype)\n",
    "z = u\n",
    "zminus = z - 1\n",
    "\n",
    "\n",
    "# Merge zminus and z to find beta candidates \n",
    "merged_tensor = torch.cat((z, zminus), dim=1)\n",
    "merged_sorted_tensor, _ = torch.sort(merged_tensor, descending=True)\n",
    "# merged_sorted_tensor are candidate for beta (referering  to the 2m distinct pairs )\n",
    "merged_sorted_tensor = merged_sorted_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2857efd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z input\n",
      "tensor([[ 0.7709, -0.4365,  0.9997, -0.8282, -3.0413,  0.8198, -0.0842, -1.0837,\n",
      "          0.3916,  0.3448]])\n",
      "Beta Candidate List\n",
      "tensor([ 9.9969e-01,  8.1984e-01,  7.7087e-01,  3.9159e-01,  3.4476e-01,\n",
      "        -3.1495e-04, -8.4162e-02, -1.8016e-01, -2.2913e-01, -4.3646e-01,\n",
      "        -6.0841e-01, -6.5524e-01, -8.2824e-01, -1.0837e+00, -1.0842e+00,\n",
      "        -1.4365e+00, -1.8282e+00, -2.0837e+00, -3.0413e+00, -4.0413e+00])\n"
     ]
    }
   ],
   "source": [
    "print(\"Z input\")\n",
    "print(z)\n",
    "\n",
    "print(\"Beta Candidate List\")\n",
    "print(merged_sorted_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d2064312",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []  # will store (U_count, W_count) as *counts*\n",
    "for beta in merged_sorted_tensor:\n",
    "    b = beta.item()\n",
    "\n",
    "    # equation 24\n",
    "    # masks over sorted z\n",
    "    u_ge_mask = (z >= b + 1)      # will be True for indices [0 .. U-1]\n",
    "    w_gt_mask = (z > b)           # will be True for indices [0 .. W-1]\n",
    "\n",
    "    U = int(u_ge_mask.sum().item())   # <-- counts, not indices\n",
    "    W = int(w_gt_mask.sum().item())   # <-- counts, not indices\n",
    "    if W <= U:                        # need at least one fractional slot\n",
    "        continue\n",
    "\n",
    "    pairs.append((U, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "282352d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U,W pairs from all beta candidates\n",
      "[(0, 1), (0, 2), (0, 3), (0, 4), (1, 5), (1, 5), (2, 6), (3, 6), (3, 6), (4, 7), (5, 7), (5, 7), (5, 8), (5, 9), (6, 9), (8, 9)]\n"
     ]
    }
   ],
   "source": [
    "print(\"U,W pairs from all beta candidates\")\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be65e33",
   "metadata": {},
   "source": [
    "\n",
    "![Algorithm 1](./asset/algorithm1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "45845f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort z (descending) for the same batch\n",
    "z, _ = torch.sort(z, descending=True)\n",
    "z = z[0]                                  # 1D scores (length m)\n",
    "m = z.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c0dcf297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre comute the cumulative sum\n",
    "z_cum = torch.cumsum(z, dim=0)            # S[t] = sum_{i=0..t} z[i]\n",
    "z_pad = torch.cat([z, z.new_tensor([-float('inf')])])  # z[m] = -inf for right-guard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6399163",
   "metadata": {},
   "source": [
    "##### within iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "806f850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = 0 \n",
    "W = 1\n",
    "seg_sum = z_cum[W-1] - (z_cum[U-1] if U > 0 else z_cum.new_zeros(()))\n",
    "tau_cand = (seg_sum + (U - k)) / (W - U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274cf1bf",
   "metadata": {},
   "source": [
    "![Condition](./asset/condition.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6a79be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval checks (use sentinels; interpret counts -> 0-based indices)\n",
    "left_cond  = (z[W-1] > tau_cand) if W >= 1 else True\n",
    "right_cond = (tau_cand >= z_pad[W])  # z_pad[W] is safe for W==m\n",
    "up_cond    = (z[U-1] >= tau_cand + 1) if U >= 1 else True\n",
    "down_cond  = ((tau_cand + 1) > z_pad[U])  # z_pad[U] safe for U==m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "4f2ffffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(False), True, tensor(False))"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_cond , right_cond , up_cond , down_cond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72667686",
   "metadata": {},
   "source": [
    "then break if all true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e01e4b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "426c43d6",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "2489597e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'Tensor' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[362], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m         tau \u001b[38;5;241m=\u001b[39m tau_cand\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[43mz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum p =\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(p\u001b[38;5;241m.\u001b[39msum()))\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'Tensor' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# scan in the paper's order: descending in beta (pairs already collected that way)\n",
    "tau = None\n",
    "k = 3.5\n",
    "for U, W in pairs:\n",
    "    # sums over i in [U .. W-1] using zero-based inclusive prefix sums:\n",
    "    # sum_{U..W-1} z = z_cum[W-1] - (z_cum[U-1] if U>0 else 0)\n",
    "    seg_sum = z_cum[W-1] - (z_cum[U-1] if U > 0 else z_cum.new_zeros(()))\n",
    "    tau_cand = (seg_sum + (U - k)) / (W - U)\n",
    "\n",
    "    # interval checks (use sentinels; interpret counts -> 0-based indices)\n",
    "    left_ok  = (z[W-1] > tau_cand) if W >= 1 else True\n",
    "    right_ok = (tau_cand >= z_pad[W])  # z_pad[W] is safe for W==m\n",
    "    up_ok    = (z[U-1] >= tau_cand + 1) if U >= 1 else True\n",
    "    down_ok  = ((tau_cand + 1) > z_pad[U])  # z_pad[U] safe for U==m\n",
    "\n",
    "    if left_ok and right_ok and up_ok and down_ok:\n",
    "        tau = tau_cand\n",
    "        break\n",
    "    \n",
    "p = torch.clamp(z - tau, 0, 1)\n",
    "print(\"sum p =\", float(p.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "4e28ddf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.8631, 0.8141, 0.4348, 0.3880, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f617ae",
   "metadata": {},
   "source": [
    "### Assuming p is correct, sum of p == k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "69749214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (BATCH X SEQ X DIM)\n",
    "# output of q, k ,v single head\n",
    "\n",
    "q = torch.randn(BATCH, 1, SEQ, DIM, dtype=dtype)\n",
    "key = torch.randn(BATCH, 1, SEQ, DIM, dtype=dtype)\n",
    "v = torch.randn(BATCH, 1, SEQ, DIM, dtype=dtype)\n",
    "\n",
    "x = torch.randn(BATCH, SEQ , DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9f756",
   "metadata": {},
   "source": [
    "![Selection_matrix](./asset/selecton_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e13173a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.7709, -0.4365,  0.9997, -0.8282, -3.0413,  0.8198, -0.0842, -1.0837,\n",
       "           0.3916,  0.3448]]),\n",
       " 3.5)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c06734c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP K mask\n",
      "tensor([[1., 0., 1., 0., 0., 1., 0., 0., 0., 0.]])\n",
      "Soft selection\n",
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "def topk_mask(u, k):\n",
    "    \"\"\"\n",
    "    u: (B, T) importance scores up to current position i\n",
    "    k: number of key-value pairs to select\n",
    "    returns: m_topk: binary mask (B, T)\n",
    "    \"\"\"\n",
    "    B, T = u.shape\n",
    "    m_topk = torch.zeros_like(u, dtype=torch.float32)\n",
    "\n",
    "    # select top-k indices\n",
    "    topk_vals, topk_idx = torch.topk(u, min(k, T), dim=1)\n",
    "    m_topk[torch.arange(B).unsqueeze(1), topk_idx] = 1.0\n",
    "    return m_topk\n",
    "\n",
    "def mask_select_diag( msparsek, mtopk):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        msparsek: Tensor of shape (T,) or (1, T) with soft scores\n",
    "        mtopk: Tensor of shape (T,) or (1, T) with 0/1 hard selection\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (T, T): Diagonal matrix with masked scores\n",
    "    \"\"\"\n",
    "    # Ensure the vectors are 1D\n",
    "    msparsek = msparsek.flatten()\n",
    "    mtopk = mtopk.flatten()\n",
    "    \n",
    "    # Create diagonal matrix from msparsek\n",
    "    diag_matrix = torch.diag(msparsek)\n",
    "    \n",
    "    # Apply row mask: keep only rows where mtopk == 1\n",
    "    mask = mtopk.unsqueeze(1).expand_as(diag_matrix)  # shape (T, T)\n",
    "    masked_matrix = diag_matrix * mask.float()\n",
    "    \n",
    "    return masked_matrix\n",
    "\n",
    "\n",
    "tkmasking = topk_mask(u, int(k))\n",
    "print(\"TOP K mask\")\n",
    "print(tkmasking)\n",
    "selection_mat = mask_select_diag(p, tkmasking)\n",
    "print(\"Soft selection\")\n",
    "print(selection_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "113bd130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 10, 2]), torch.Size([1, 1, 10, 2]))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_hat = selection_mat @ key\n",
    "v_hat = selection_mat @ v\n",
    "\n",
    "k_hat.shape , v_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "13ec469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teeds\\AppData\\Local\\Temp\\ipykernel_1912\\3235830935.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(q @ k_hat.transpose(-2,-1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "p = F.softmax(q @ k_hat.transpose(-2,-1))\n",
    "p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b8bd6bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 10, 10]), torch.Size([1, 1, 10, 2]))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape , v_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5da07985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.transpose(-2,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8dfd8b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 2])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = p.transpose(-2,-1) @ v_hat\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsek_1d(z, k):\n",
    "\n",
    "\n",
    "    # Merge zminus and z to find beta candidates \n",
    "    merged_tensor = torch.cat((z, z - 1), dim=1)\n",
    "    merged_sorted_tensor, _ = torch.sort(merged_tensor, descending=True)\n",
    "    # merged_sorted_tensor are candidate for beta (referering  to the 2m distinct pairs )\n",
    "    merged_sorted_tensor = merged_sorted_tensor[0]\n",
    "\n",
    "    # Sort z (descending) for the same batch\n",
    "    z, _ = torch.sort(z, descending=True)\n",
    "    z = z[0]                                  # 1D scores (length m)\n",
    "\n",
    "    # pre comute the cumulative sum\n",
    "    z_cum = torch.cumsum(z, dim=0)            # S[t] = sum_{i=0..t} z[i]\n",
    "    z_pad = torch.cat([z, z.new_tensor([-float('inf')])])  # z[m] = -inf for right-guard\n",
    "\n",
    "\n",
    "    pairs = []  # will store (U_count, W_count) as *counts*\n",
    "    for beta in merged_sorted_tensor:\n",
    "        b = beta.item()\n",
    "\n",
    "        # equation 24\n",
    "        # masks over sorted z\n",
    "        u_ge_mask = (z >= b + 1)      # will be True for indices [0 .. U-1]\n",
    "        w_gt_mask = (z > b)           # will be True for indices [0 .. W-1]\n",
    "\n",
    "        U = int(u_ge_mask.sum().item())   # <-- counts, not indices\n",
    "        W = int(w_gt_mask.sum().item())   # <-- counts, not indices\n",
    "        if W <= U:                        # need at least one fractional slot\n",
    "            continue\n",
    "\n",
    "        pairs.append((U, W))\n",
    "\n",
    "    print(\"U,W pairs from all beta candidates\")\n",
    "    print(pairs)\n",
    "\n",
    "    \n",
    "    # scan in the paper's order: descending in beta (pairs already collected that way)\n",
    "    tau = None\n",
    "\n",
    "    for U, W in pairs:\n",
    "        # sums over i in [U .. W-1] using zero-based inclusive prefix sums:\n",
    "        # sum_{U..W-1} z = z_cum[W-1] - (z_cum[U-1] if U>0 else 0)\n",
    "        seg_sum = z_cum[W-1] - (z_cum[U-1] if U > 0 else z_cum.new_zeros(()))\n",
    "        tau_cand = (seg_sum + (U - k)) / (W - U)\n",
    "\n",
    "        # interval checks (use sentinels; interpret counts -> 0-based indices)\n",
    "        left_ok  = (z[W-1] > tau_cand) if W >= 1 else True\n",
    "        right_ok = (tau_cand >= z_pad[W])  # z_pad[W] is safe for W==m\n",
    "        up_ok    = (z[U-1] >= tau_cand + 1) if U >= 1 else True\n",
    "        down_ok  = ((tau_cand + 1) > z_pad[U])  # z_pad[U] safe for U==m\n",
    "\n",
    "        if left_ok and right_ok and up_ok and down_ok:\n",
    "            tau = tau_cand\n",
    "            break\n",
    "        \n",
    "    p = torch.clamp(z - tau, 0, 1)\n",
    "    print(\"sum p =\", float(p.sum()))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "88dd8d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.6552, 0.5831, 0.5766, 0.1068, 0.0784, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "sum p = 2.999999523162842\n"
     ]
    }
   ],
   "source": [
    "BATCH = 1\n",
    "u = torch.randn(BATCH, SEQ , dtype=dtype)\n",
    "\n",
    "p = sparsek_nd(u, 3)\n",
    "print(p)\n",
    "print(\"sum p =\", float(p.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ab2056dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH = 3\n",
    "SEQ = 10\n",
    "u = torch.randn(BATCH, SEQ , dtype=dtype)\n",
    "\n",
    "z = u \n",
    "\n",
    "\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "87f13e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n",
      "tensor([ 2.0092,  1.8055,  1.0092,  0.8055,  0.7135,  0.6731,  0.3174, -0.2865,\n",
      "        -0.3269, -0.6826, -0.8289, -0.8739, -1.2162, -1.4271, -1.4842, -1.8289,\n",
      "        -1.8739, -2.2162, -2.4271, -2.4842])\n"
     ]
    }
   ],
   "source": [
    "# Merge zminus and z to find beta candidates \n",
    "merged_tensor = torch.cat((z, z - 1), dim=1)\n",
    "print(merged_tensor.shape)\n",
    "merged_sorted_tensor, _ = torch.sort(merged_tensor, descending=True , dim=1)\n",
    "print(merged_sorted_tensor.shape)\n",
    "# merged_sorted_tensor are candidate for beta (referering  to the 2m distinct pairs )\n",
    "print(merged_sorted_tensor[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9983fbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2162, -1.4271,  0.6731, -0.8289,  1.8055, -0.8739,  0.3174, -1.4842,\n",
       "         0.7135,  2.0092])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "12da35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort z descending for each batch\n",
    "z_sorted, _ = torch.sort(z, descending=True, dim=1)  # (B, m)\n",
    "\n",
    "# Cumulative sum for each batch\n",
    "z_cum = torch.cumsum(z_sorted, dim=1)  # (B, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e30df643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0092,  1.8055,  0.7135,  0.6731,  0.3174, -0.8289, -0.8739, -1.2162,\n",
       "        -1.4271, -1.4842])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_sorted[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427de6c",
   "metadata": {},
   "source": [
    "same number different order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6237dad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10]),\n",
       " tensor([ 2.0092,  3.8147,  4.5283,  5.2013,  5.5187,  4.6898,  3.8159,  2.5997,\n",
       "          1.1726, -0.3116]))"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_cum.shape , z_cum[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c10fe873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 11])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Right-guard padding\n",
    "z_pad = torch.cat([z_sorted, z.new_full((BATCH, 1), -float('inf'))], dim=1)  # (B, m+1)\n",
    "z_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2a216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "[(0, 1), (1, 2), (2, 3), (2, 4), (3, 5), (4, 5), (5, 6), (5, 7), (5, 8), (5, 9), (6, 10), (7, 10), (7, 10), (9, 10)]\n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "2 4\n",
      "3 5\n",
      "4 5\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "6 10\n",
      "7 10\n",
      "7 10\n",
      "9 10\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'Tensor' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[356], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(tau)\n\u001b[1;32m---> 31\u001b[0m p_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[43mz_sorted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m p_out\u001b[38;5;241m.\u001b[39mappend(p_b)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'Tensor' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "p_out = []\n",
    "for b in range(BATCH):\n",
    "    pairs = []\n",
    "    print(merged_sorted_tensor.shape)\n",
    "    for beta in merged_sorted_tensor[b]:\n",
    "        bval = beta.item()\n",
    "        u_ge_mask = (z_sorted[b] >= bval + 1)\n",
    "        w_gt_mask = (z_sorted[b] > bval)\n",
    "        U = int(u_ge_mask.sum().item())\n",
    "        W = int(w_gt_mask.sum().item())\n",
    "        if W <= U:\n",
    "            continue\n",
    "        pairs.append((U, W))\n",
    "    tau = None\n",
    "    print(pairs)\n",
    "    for U, W in pairs:\n",
    "        print(U, W)\n",
    "        seg_sum = z_cum[b, W-1] - (z_cum[b, U-1] if U > 0 else 0)\n",
    "        tau_cand = (seg_sum + (U - k)) / (W - U)\n",
    "\n",
    "        left_ok  = (z_sorted[b, W-1] > tau_cand) if W >= 1 else True\n",
    "        right_ok = (tau_cand >= z_pad[b, W])\n",
    "        up_ok    = (z_sorted[b, U-1] >= tau_cand + 1) if U >= 1 else True\n",
    "        down_ok  = ((tau_cand + 1) > z_pad[b, U])\n",
    "\n",
    "        if left_ok and right_ok and up_ok and down_ok:\n",
    "            tau = tau_cand\n",
    "            break\n",
    "    print(tau)\n",
    "    p_b = torch.clamp(z_sorted[b] - tau, 0, 1)\n",
    "    p_out.append(p_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67448ed8",
   "metadata": {},
   "source": [
    "Need a fallback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a25b3858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14, 2)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_paris) , len(list_of_paris[0]), len(list_of_paris[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3f226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 2), (2, 3), (2, 4), (3, 5), (4, 5), (5, 6), (5, 7), (5, 8), (5, 9), (6, 10), (7, 10), (7, 10), (9, 10)]\n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "2 4\n",
      "3 5\n",
      "4 5\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "6 10\n",
      "7 10\n",
      "7 10\n",
      "9 10\n",
      "[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 6), (2, 6), (3, 6), (3, 6), (3, 7), (4, 8), (4, 8), (5, 9), (6, 9), (6, 9), (7, 10), (7, 10), (9, 10), (9, 10)]\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "1 6\n",
      "[(0, 1), (0, 2), (0, 3), (1, 4), (1, 4), (1, 5), (1, 6), (1, 7), (2, 8), (2, 8), (2, 9), (2, 10), (3, 10), (4, 10), (6, 10), (7, 10), (8, 10), (9, 10), (9, 10)]\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "1 4\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "2 8\n",
      "2 8\n",
      "2 9\n",
      "2 10\n",
      "3 10\n",
      "4 10\n",
      "6 10\n",
      "7 10\n",
      "8 10\n",
      "9 10\n",
      "9 10\n"
     ]
    }
   ],
   "source": [
    "list_tau = []\n",
    "for b in range(BATCH):\n",
    "    pairs = list_of_paris[b]\n",
    "    tau = None\n",
    "    for U, W in pairs:\n",
    "        seg_sum = z_cum[b, W-1] - (z_cum[b, U-1] if U > 0 else 0)\n",
    "        tau_cand = (seg_sum + (U - k)) / (W - U)\n",
    "\n",
    "        left_ok  = (z_sorted[b, W-1] > tau_cand) if W >= 1 else True\n",
    "        right_ok = (tau_cand >= z_pad[b, W])\n",
    "        up_ok    = (z_sorted[b, U-1] >= tau_cand + 1) if U >= 1 else True\n",
    "        down_ok  = ((tau_cand + 1) > z_pad[b, U])\n",
    "\n",
    "        if left_ok and right_ok and up_ok and down_ok:\n",
    "            tau = tau_cand\n",
    "            list_tau.append(tau)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "18f60ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.1836)]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f75183",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def learnable_selection(input, w_score , epsilon):\n",
    "    zs = torch.sort(input=input, dim=dim, descending=True)[0]\n",
    "    range = torch.arange(start=1, end=number_of_logits + 1, step=1, device=device, dtype=input.dtype).view(1, -1)\n",
    "    range = range.expand_as(zs)\n",
    "\n",
    "    # Determine sparsity of projectio\n",
    "    u = zs  @ w_score + range * epsilon\n",
    "\n",
    "    return u \n",
    "\n",
    "m = input.size(1)\n",
    "\n",
    "dim = 1\n",
    "cumulative_sum_zs = torch.cumsum(zs, dim)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

‚úÖ Completed
- [x] Add W&B  
- [x] Restructure codebase  
- [x] Put into M3  
- [x] Use Docker to train  

‚è≥ Next Steps

üîß Development / Infrastructure  
- [ ] Use MDN workstation for training  
- [ ] Add GitHub Action ‚Üí trigger training automatically when uploading  

‚ö° Model Optimization  
- [ ] Implement quantisation  
- [ ] Implement pruning  

ü§ñ Transformer Architectures & Mechanisms  
- [ ] Implement Causal Transformers  
- [ ] Compare Encoder-Decoder vs. Decoder-Only  
- [ ] Implement and test attention mechanisms:  
  - [ ] Vanilla self-attention  
  - [ ] Sparse attention  
  - [ ] Local attention  

üìö Reading / Research  
- [ ] Read & take notes on:  
  - [ ] https://www.alphaxiv.org/abs/2505.08348  
  - [ ] https://www.mdpi.com/1999-4893/17/2/76  
  - [ ] https://link.springer.com/article/10.1007/s10915-022-01939-z  
  - [ ] https://www.alphaxiv.org/abs/2405.13218  
  - [ ] https://www.alphaxiv.org/abs/2402.19469  
  - [ ] https://www.alphaxiv.org/abs/2409.15046  
  - [ ] https://www.alphaxiv.org/abs/2501.02007  
  - [ ] https://ieeexplore.ieee.org/document/10313200  
